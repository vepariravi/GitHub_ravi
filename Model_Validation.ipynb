{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood Transfusion Service Center Data Set.Â¶\n",
    "### Data Set Information:\n",
    "\n",
    "To demonstrate the RFMTC marketing model (a modified version of RFM), this study adopted the donor database of Blood Transfusion Service Center in Hsin-Chu City in Taiwan. The center passes their blood transfusion service bus to one university in Hsin-Chu City to gather blood donated about every three months. To build a FRMTC model, we selected 748 donors at random from the donor database. These 748 donor data, each one included R (Recency - months since last donation), F (Frequency - total number of donation), M (Monetary - total blood donated in c.c.), T (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood).\n",
    "\n",
    "Source: UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the dataset into train and test samples.\n",
    "\n",
    "## separating the independents and dependents \n",
    "\n",
    "X = df.drop(columns='made_donation_in_march_2007')\n",
    "y = df.made_donation_in_march_2007\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
    "\n",
    "df = df.rename(columns={'Recency (months)' : 'Recency - months since last donation',\n",
    "                    'Frequency (times)' : 'Frequency - total number of donation',\n",
    "                    'Monetary (c.c. blood)' : 'Monetary - total blood donated in c.c.',\n",
    "                    'Time (months)' : 'Time - months since first donation' ,\n",
    "                    'whether he/she donated blood in March 2007' : 'made_donation_in_march_2007'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recency - months since last donation      0\n",
       "Frequency - total number of donation      0\n",
       "Monetary - total blood donated in c.c.    0\n",
       "Time - months since first donation        0\n",
       "made_donation_in_march_2007               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.768271\n",
      "1    0.231729\n",
      "Name: made_donation_in_march_2007, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.768270944741533"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get quick initial metrics estimate.\n",
    "\n",
    "# Using simple pandas value counts method\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# Using sklearn accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "majority_class = y_train.mode()[0]\n",
    "prediction = np.full(shape=y_train.shape, \n",
    "                     fill_value=majority_class)\n",
    "\n",
    "accuracy_score(y_train, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing, Feature selection and Model selection.\n",
    "\n",
    "# Imports for pipeline\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## create a pipeline\n",
    "\n",
    "pipeline = make_pipeline(\\\n",
    "                         RobustScaler(),\n",
    "                         SelectKBest(f_classif),\n",
    "                         LogisticRegression(solver='lbfgs'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('selectkbest', SelectKBest(k=10, score_func=<function f_classif at 0x122dfa158>)), ('logisticregression', LogisticRegression(C=1.0, clas...nalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'selectkbest__k': [1, 2, 3, 4], 'logisticregression__class_weight': [None, 'balanced'], 'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Validation\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'selectkbest__k': [1, 2, 3, 4],\n",
    "    'logisticregression__class_weight': [None,'balanced'],\n",
    "    'logisticregression__C': [.0001, .001, .01, .1, 1.0, 10.0, 100.00, 1000.0, 10000.0]\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7807486631016043\n",
      "Best Parameters {'logisticregression__C': 1.0, 'logisticregression__class_weight': None, 'selectkbest__k': 4}\n",
      "Features selected:\n",
      "Recency - months since last donation\n",
      "Frequency - total number of donation\n",
      "Monetary - total blood donated in c.c.\n",
      "Time - months since first donation\n",
      "\n",
      "Features not selected:\n"
     ]
    }
   ],
   "source": [
    "# interpret the results.\n",
    "\n",
    "# best cross validation score\n",
    "\n",
    "print('Cross validation score:', gridsearch.best_score_)\n",
    "\n",
    "# Best parameters which resulted in the best score\n",
    "\n",
    "print('Best Parameters',gridsearch.best_params_)\n",
    "\n",
    "# Which features were selected?\n",
    "selector = gridsearch.best_estimator_.named_steps['selectkbest']\n",
    "all_names = X_train.columns\n",
    "selected_mask = selector.get_support()\n",
    "selected_names = all_names[selected_mask]\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print('Features selected:')\n",
    "for name in selected_names:\n",
    "    print(name)\n",
    "\n",
    "print()\n",
    "print('Features not selected:')\n",
    "for name in unselected_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test data set 0.7540106951871658\n"
     ]
    }
   ],
   "source": [
    "#Get the best model and check it against test data set.\n",
    "\n",
    "# Predict with X_test features\n",
    "\n",
    "y_pred = gridsearch.predict(X_test)\n",
    "\n",
    "#compare predictions to y_test labels.\n",
    "\n",
    "test_score = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy score on test data set', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = gridsearch.best_estimator_.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=4, score_func=<function f_classif at 0x122dfa158>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
